new_order <- sample(nrow(Iris))
Iris <- Iris[new_order]
## split this shuffled dataset in two: a training set with about 90% of the data,
## and a test set with about 10%
train <- Iris[1:135, list(Petal.Length, Petal.Width, Species)] #training set
test <- Iris[136:150, list(Petal.Length, Petal.Width, Species)] #testing set
## Run the k-NN algorithm, with k=3 to start with.
knn_output1 <- kknn(Species~., train, test, k=3)
test[, predicted_species:=knn_output1$fitted.values] #add the output to the testing test
#plotA predicted vs dark species for knn, k=3
ggplot(test, aes(x=Petal.Length, y=Petal.Width)) +
geom_point(aes(color=Species), size=5, alpha=0.3) +
geom_point(aes(color=predicted_species)) +
geom_point(data=train, aes(color=Species), alpha=0.4, shape=2) +
labs(title="Predicted (dark) vs Real (opaque) Species, k=3")
## test a few other values of k, using for loop.
k_values <- c(5, 7, 9) #list of k values
for (this_k in k_values){
## run k-nn
knn_output2 <- kknn(Species~., train, test, k=this_k)
## predict a new rank
test[, predicted_species:=knn_output2$fitted.values]
## predict results
plot <- ggplot(test, aes(x=Petal.Length, y=Petal.Width)) +
geom_point(aes(color=Species), size=5, alpha=0.3) +
geom_point(aes(color=predicted_species)) +
geom_point(data=train, aes(color=Species), alpha=0.4, shape=2) +
labs(title=paste0("Predicted (dark) vs Real (opaque) Species, k=", this_k))
print(plot)
## Print out how many times it mispredicts
number_wrong = nrow(test[Species!=predicted_species])
pct_wrong = number_wrong/nrow(test)
print(paste0("With k=", this_k, " k-NN makes ", number_wrong, " incorrect predictions, ", pct_wrong, " percent."))
}
k_values <- c(5, 7, 9) #list of k values
for (this_k in k_values){
## run k-nn
knn_output2 <- kknn(Species~., train, test, k=this_k)
## predict a new rank
test[, predicted_species:=knn_output2$fitted.values]
## predict results
plot <- ggplot(test, aes(x=Petal.Length, y=Petal.Width)) +
geom_point(aes(color=Species), size=5, alpha=0.3) +
geom_point(aes(color=predicted_species)) +
geom_point(data=train, aes(color=Species), alpha=0.4, shape=2) +
labs(title=paste0("Predicted (dark) vs Real (opaque) Species, k=", this_k))
print(plot)
## Print out how many times it mispredicts
number_wrong = nrow(test[Species!=predicted_species])
pct_wrong = number_wrong/nrow(test)
print(paste0("With k=", this_k, " k-NN makes ", number_wrong, " incorrect predictions, ", pct_wrong, " percent."))
}
## Load the libraries
library(car)
library(ggplot2)
library(data.table)
data("Prestige")
Prestige <-data.table(Prestige)
ggplot(Prestige, aes(x=education, y=prestige)) + geom_point(aes(colour=women)) + labs(title="Education by Prestige and Women",
x="Education",
y="Prestige")
#Scatter
#Scatter plot of Prestige with education and type showing the trendline with standard error
ggplot(Prestige, aes(x=education, y=prestige)) + geom_point(aes(colour=type)) + geom_smooth(method=lm, se=T) + labs(title="Education by Prestige and Type",
x="Education",
y="Prestige")
#Scatter plot of Prestige with income and type showing the trendline with standard error
ggplot(Prestige, aes(x=income, y=prestige)) + geom_point(aes(colour=type), alpha=0.5) + geom_smooth(method=lm, se=T) + labs(title="Income by Prestige and Type",
x="Income",
y="Prestige")
#Scatter plot of Prestige with log transformation of income, women and type using facet
ggplot(Prestige, aes(x=log2(income), y=prestige)) + geom_point(aes(colour=women)) + facet_grid(~type) + labs(title="Log2(Income) by Prestige, Income, Women and Type",
x="Log2(Income)", y="Prestige")
#Bar plot of Income vs. Women
ggplot(Prestige, aes(women,income)) + geom_bar(position="dodge", stat="identity", width=0.75)
#Scatterplot matrix to see how each variable relates to the other
scatterplotMatrix(~ prestige + log2(income) + education + women, span=0.7, id.n=0, data=Prestige)
ggplot(Prestige, aes(income)) + geom_histogram(aes(y =..density..),breaks=seq(0, 26000, by = 500),
col="blue", fill="green", alpha = 0.2) + labs(title="Histogram for Income") + labs(x="Income", y="Count") + geom_density(col=2)
library(gdata)
library(XLConnect)
install.packages("gdata")
library(gdata)
mydata = read.xls("udist_play_98105.xls")
mydata = read.csv("udist_play_98105.xls")
udist_play_98105 <- read.csv("~/Desktop/udist_play_98105.csv")
View(udist_play_98105)
udist <- data.table(udist_play_98105)
data("udist_play_98105")
library(data.table)
library(ggplot2)
library(datasets)
data("udist_play_98105")
udist <- data.table(udist_play_98105)
udist
head(udist)
View(udist_play_98105)
library(kknn) # for k-NN; if you need to install the packages first, use install.packages("kknn")
library(stats)
View(udist_play_98105)
for_kmeans <- udist[, list(alternative, rock)]
output <- kmeans(for_kmeans, centers=2)
udist[, kmean_species:=output$cluster]
ggplot(udist, aes(x=alternative, y=rock, color=factor(kmean_species))) +
geom_point() +
labs(title="Predicted Clusters, K=2")
for_kmeans <- udist[, list(alternative, rock)]
output <- kmeans(for_kmeans, centers=3)
udist[, kmean_species:=output$cluster]
ggplot(udist, aes(x=alternative, y=rock, color=factor(kmean_species))) +
geom_point() +
labs(title="Predicted Clusters, K=3")
View(udist_play_98105)
data("udist_play_98105")
udist <- data.table(udist_play_98105)
head(udist)
library(kknn) # for k-NN; if you need to install the packages first, use install.packages("kknn")
library(stats)
for_kmeans <- udist[, list(alternative, rock)]
output <- kmeans(for_kmeans, centers=3)
udist[, kmean_species:=output$cluster]
ggplot(udist, aes(x=alternative, y=rock, color=factor(kmean_species))) +
geom_point() +
labs(title="Predicted Clusters, K=3")
data("udist_play_98105")
udist <- data.table(udist_play_98105)
head(udist)
library(kknn) # for k-NN; if you need to install the packages first, use install.packages("kknn")
library(stats)
library(ggplot2)
for_kmeans <- udist[, list(alternative, rock)]
output <- kmeans(for_kmeans, centers=3)
udist[, kmean_species:=output$cluster]
ggplot(udist, aes(x=alternative, y=rock, color=factor(kmean_species))) +
geom_point() +
labs(title="Predicted Clusters, K=3")
set.seed(250)
new_order <- sample(nrow(udist))
udist <- udist[new_order]
train <- udist[1:18, list(alternative, rock, companies)] #training set
test <- udist[19:20, list(alternative, rock, companies)] #testing set
View(udist_play_98105)
View(udist)
train <- udist[1:18, list(alternative, rock, companies)]
View(Iris)
test <- udist[19:20, list(alternative, rock, companies)]
udist
udist <- NULL
new_order <- NULL
udist <- udist[new_order]
udist <- NULL
udist_play_98105 <- NULL
data("udist_play_98105")
udist <- data.table(udist_play_98105)
library(kknn) # for k-NN; if you need to install the packages first, use install.packages("kknn")
library(stats)
library(ggplot2)
library(data.table)
data("udist_play_98105")
udist <- data.table(udist_play_98105)
udist_play_98105 <- read.table("~/Desktop/udist_play_98105.xlsx", header=TRUE, quote="\"")
View(udist_play_98105)
udist_play_98105 <- read.csv("~/Desktop/udist_play_98105.csv")
View(udist_play_98105)
data("udist_play_98105")
udist <- data.table(udist_play_98105)
View(udist)
head(udist)
set.seed(250)
new_order <- sample(nrow(udist))
udist <- udist[new_order]
train <- udist[1:18, list(alternative, rock, companies)]
test <- udist[19:20, list(alternative, rock, companies)]
knn_output1 <- kknn(companies~., train, test, k=3)
test[, predicted_species:=knn_output1$fitted.values]
ggplot(test, aes(x=alternative, y=rock)) +
geom_point(aes(color=companies), size=5, alpha=0.3) +
geom_point(aes(color=predicted_species)) +
geom_point(data=train, aes(color=companies), alpha=0.4, shape=2) +
labs(title="Predicted (dark) vs Real (opaque) Companies, k=3")
k_values <- c(5, 7, 9)
for (this_k in k_values){
## run k-nn
knn_output2 <- kknn(companies~., train, test, k=this_k)
## predict a new rank
test[, predicted_species:=knn_output2$fitted.values]
## predict results
plot <- ggplot(test, aes(x=alternative, y=rock)) +
geom_point(aes(color=companies), size=5, alpha=0.3) +
geom_point(aes(color=predicted_species)) +
geom_point(data=train, aes(color=companies), alpha=0.4, shape=2) +
labs(title=paste0("Predicted (dark) vs Real (opaque) companies, k=", this_k))
print(plot)
## Print out how many times it mispredicts
number_wrong = nrow(test[companies!=predicted_species])
pct_wrong = number_wrong/nrow(test)
print(paste0("With k=", this_k, " k-NN makes ", number_wrong, " incorrect predictions, ", pct_wrong, " percent."))
}
rm(list=ls())
data("udist_play_98105")
udist <- data.table(udist_play_98105)
head(udist)
library(kknn) # for k-NN; if you need to install the packages first, use install.packages("kknn")
library(stats)
library(ggplot2)
library(data.table)
set.seed(250)
new_order <- sample(nrow(udist))
udist <- udist[new_order]
## split this shuffled dataset in two: a training set with about 90% of the data,
## and a test set with about 10%
train <- udist[1:18, list(alternative, rock, companies)] #training set
test <- udist[19:20, list(alternative, rock, companies)] #testing set
## Run the k-NN algorithm, with k=3 to start with.
knn_output1 <- kknn(companies~., train, test, k=3)
test[, predicted_species:=knn_output1$fitted.values] #add the output to the testing test
#plotA predicted vs dark species for knn, k=3
ggplot(test, aes(x=alternative, y=rock)) +
geom_point(aes(color=companies), size=5, alpha=0.3) +
geom_point(aes(color=predicted_species)) +
geom_point(data=train, aes(color=companies), alpha=0.4, shape=2) +
labs(title="Predicted (dark) vs Real (opaque) Companies, k=3")
udist
udist_play_98105 <- read.csv("~/Desktop/udist_play_98105.csv")
View(udist_play_98105)
data("udist_play_98105")
udist <- data.table(udist_play_98105)
head(udist)
set.seed(250)
new_order <- sample(nrow(udist))
udist <- udist[new_order]
## split this shuffled dataset in two: a training set with about 90% of the data,
## and a test set with about 10%
train <- udist[1:18, list(alternative, rock, companies)] #training set
test <- udist[19:20, list(alternative, rock, companies)] #testing set
## Run the k-NN algorithm, with k=3 to start with.
knn_output1 <- kknn(companies~., train, test, k=3)
test[, predicted_species:=knn_output1$fitted.values] #add the output to the testing test
#plotA predicted vs dark species for knn, k=3
ggplot(test, aes(x=alternative, y=rock)) +
geom_point(aes(color=companies), size=5, alpha=0.3) +
geom_point(aes(color=predicted_species)) +
geom_point(data=train, aes(color=companies), alpha=0.4, shape=2) +
labs(title="Predicted (dark) vs Real (opaque) Companies, k=3")
for_kmeans <- udist[, list(alternative, rock)]
output <- kmeans(for_kmeans, centers=3)
udist[, kmean_species:=output$cluster]
ggplot(udist, aes(x=alternative, y=rock, color=factor(kmean_species))) +
geom_point() +
labs(title="Predicted Clusters, K=3")
ggplot(Prestige, aes(prestige)) + geom_histogram(aes(y =..density..),
col="blue", fill="green", alpha = 0.2) + labs(title="Histogram for Prestige") + labs(x="Prestige", y="Count")+
geom_density(col=2)
library(ggplot2)
ggplot(Prestige, aes(prestige)) + geom_histogram(aes(y =..density..),
col="blue", fill="green", alpha = 0.2) + labs(title="Histogram for Prestige") + labs(x="Prestige", y="Count")+
geom_density(col=2)
#Histogram of income
ggplot(Prestige, aes(income)) + geom_histogram(aes(y =..density..),breaks=seq(0, 26000, by = 500),
col="blue", fill="green", alpha = 0.2) + labs(title="Histogram for Income") + labs(x="Income", y="Count") + geom_density(col=2)
newdata <- Prestige[,list(income,education)]
summary(newdata)
newdata <- Prestige[,list(income,education)]
Prestige
#Histogram of Prestige
ggplot(Prestige, aes(prestige)) + geom_histogram(aes(y =..density..),
col="blue", fill="green", alpha = 0.2) + labs(title="Histogram for Prestige") + labs(x="Prestige", y="Count")+
geom_density(col=2)
newdata <- Prestige[,list(income,education)]
View(Prestige)
newdata <- Prestige[,list(income,education)]
newdata <- Prestige[,list(income,education)]
summary(newdata)
rm(list=ls())
## Load the libraries
library(car)
library(ggplot2)
library(data.table)
library(corrplot)
library(kknn)
library(stats)
data("Prestige")
Prestige <-data.table(Prestige)
sd(Prestige$education)
str(Prestige)
summary(Prestige)
sd(Prestige$education) #standard deviation of education
sd(Prestige$income) #standard deviation of income
sd(Prestige$prestige)
sd(Prestige$education) #standard deviation of education
sd(Prestige$income) #standard deviation of income
sd(Prestige$prestige) #standard deviation of prestige
#Scatter plot of Prestige with education and women
ggplot(Prestige, aes(x=education, y=prestige)) + geom_point(aes(colour=women)) + labs(title="Education by Prestige and Women",
x="Education",
y="Prestige")
summary(Prestige)
newdata <- Prestige[,list(income,education)]
summary(newdata)
ggplot(newdata, aes(income)) + geom_histogram() + labs(title="Histogram for Average Income") + labs(x="Income", y="Count")
#Histogram of education
ggplot(newdata, aes(education)) + geom_histogram() + labs(title="Histogram for Average Years of Education") + labs(x="Education", y="Count")
# Create a plot of the subset data.
ggplot(newdata, aes(x=education, y=income)) + geom_point()+ labs(title="Relationship between Income and Education",x="Income", y="Education")
#
education_regression = lm(income ~ education, data = newdata)
summary(education_regression)
newdata[,predicted_regression:= predict(education_regression)]
ggplot(newdata, aes(x=newdata$education)) + geom_point(aes(y=newdata$income)) + geom_line(aes(y=newdata$predicted_regression))
#Scatter plot of Prestige with income and type showing the trendline with standard error
ggplot(Prestige, aes(x=income, y=prestige)) + geom_point(aes(colour=type), alpha=0.5) + geom_smooth(method=lm, se=T) + labs(title="Income by Prestige and Type",
x="Income",
y="Prestige")
ggplot(newdata, aes(income)) + geom_histogram() + labs(title="Histogram for Average Income") + labs(x="Income", y="Count")
ggplot(newdata, aes(education)) + geom_histogram() + labs(title="Histogram for Average Years of Education") + labs(x="Education", y="Count")
#Histogram of income
ggplot(Prestige, aes(income)) + geom_histogram(aes(y =..density..),breaks=seq(0, 26000, by = 500),
col="blue", fill="green", alpha = 0.2) + labs(title="Histogram for Income") + labs(x="Income", y="Count") + geom_density(col=2)
ggplot(Prestige, aes(prestige)) + geom_histogram(aes(y =..density..),
col="blue", fill="green", alpha = 0.2) + labs(title="Histogram for Prestige") + labs(x="Prestige", y="Count")+
geom_density(col=2)
#Histogram of income
ggplot(Prestige, aes(income)) + geom_histogram(aes(y =..density..),breaks=seq(0, 26000, by = 500),
col="blue", fill="green", alpha = 0.2) + labs(title="Histogram for Income") + labs(x="Income", y="Count") + geom_density(col=2)
head(Prestige) #first 6 rows of the dataset
tail(Prestige) #last 6 rows of the dataset
names(Prestige) #print the variables of the data set
head(Prestige) #first 6 rows of the dataset
names(Prestige) #print the variables of the data set
#Scatter plot of Prestige with income and type showing the trendline with standard error
ggplot(Prestige, aes(x=income, y=prestige)) + geom_point(aes(colour=type), alpha=0.5) + geom_smooth(method=lm, se=T) + labs(title="Income by Prestige and Type",
x="Income",
y="Prestige")
#Scatter plot of Prestige with income and type showing the trendline with standard error
ggplot(Prestige, aes(x=income, y=education)) + geom_point(aes(colour=type), alpha=0.5) + geom_smooth(method=lm, se=T) + labs(title="Income by Education and Type",
x="Income",
y="Education")
education_regression = lm(income ~ education, data = newdata)
summary(education_regression)
newdata[,predicted_regression:= predict(education_regression)]
ggplot(newdata, aes(x=newdata$education)) + geom_point(aes(y=newdata$income)) + geom_line(aes(y=newdata$predicted_regression))
newdata[,predicted_regression:= predict(education_regression)]
ggplot(newdata, aes(x=newdata$education)) + geom_point(aes(y=newdata$income)) + geom_line(aes(y=newdata$predicted_regression)) + labs(title="Income by Education",
x="Income",
y="Education")
#Scatter plot of Prestige with income and type showing the trendline with standard error
ggplot(Prestige, aes(x=income, y=education)) + geom_point(aes(colour=type), alpha=0.5) + geom_smooth(method=lm, se=T) + labs(title="Income by Education and Type",
x="Income",
y="Education")
newdata[,predicted_regression:= predict(education_regression)]
ggplot(newdata, aes(x=newdata$education)) + geom_point(aes(y=newdata$income)) + geom_line(aes(y=newdata$predicted_regression)) + labs(title="Education by Income",
x="Education",
y="Income")
plot(prestige_regression, pch=16, which=1)
plot(education_regression, pch=16, which=1)
newdata2 <- Prestige[,list(income,prestige)]
summary(newdata2)
prestige_regression = lm(prestige ~ income, data = newdata2)
summary(prestige_regression)
education_regression = lm(income ~ education, data = newdata)
summary(education_regression)
newdata2[,predicted_regression2:= predict(prestige_regression)]
ggplot(Prestige, aes(x=newdata2$income)) + geom_point(aes(y=newdata2$prestige)) + geom_line(aes(y=newdata2$predicted_regression2))
plot(prestige_regression, pch=16, which=1)
multidata <- Prestige[,list(income,education,women,prestige)]
summary(multidata)
plot(multidata, pch=16, col="blue", main="Matrix Scatterplot of Income, Education, Women and Prestige")
multi_regression = lm(income ~ education + prestige + women, data=multidata)
summary(multi_regression)
newdatacor = cor(multidata[1:4])
corrplot(newdatacor, method = "number")
multi_regression = lm(income ~ education + prestige + women, data=multidata)
summary(multi_regression)
multi_regression2 = lm(income ~ prestige + women, data=multidata)
summary(multi_regression2)
plot(multi_regression2, pch=16, which=1)
multi_regression2 = lm(income ~ prestige + women, data=multidata)
summary(multi_regression2)
multi_regression3 = lm(log(income) ~ prestige + women, data=multidata)
summary(multi_regression3)
plot(multi_regression3, pch=16, which=1)
set.seed(250)
new_order <- sample(nrow(Prestige))
Prestige <- Prestige[new_order]
train <- Prestige[1:92, list(income, women, type)] #training set
test <- Prestige[93:102, list(income, women, type)] #testing set
knn_output1 <- kknn(type~., train, test, k=3)
test[, predicted_type:=knn_output1$fitted.values] #add the output to the testing test
#plotA predicted vs dark type for knn, k=3
ggplot(test, aes(x=women, y=income)) +
geom_point(aes(color=type), size=5, alpha=0.3) +
geom_point(aes(color=predicted_type)) +
geom_point(data=train, aes(color=type), alpha=0.4, shape=2) +
labs(title="Predicted (dark) vs Real (opaque) Type, k=3")
set.seed(250)
k_values <- c(5, 7, 9) #list of k values
for (this_k in k_values){
## run k-nn
knn_output2 <- kknn(type~., train, test, k=this_k)
## predict a new rank
test[, predicted_type:=knn_output2$fitted.values]
## predict results
plot <- ggplot(test, aes(x=women, y=income)) +
geom_point(aes(color=type), size=5, alpha=0.3) +
geom_point(aes(color=predicted_type)) +
geom_point(data=train, aes(color=type), alpha=0.4, shape=2) +
labs(title=paste0("Predicted (dark) vs Real (opaque) type, k=", this_k))
print(plot)
## Print out how many times it mispredicts
number_wrong = nrow(test[type!=predicted_type])
pct_wrong = number_wrong/nrow(test)
print(paste0("With k=", this_k, " k-NN makes ", number_wrong, " incorrect predictions, ", pct_wrong, " percent."))
}
mydata <- for_kmeans
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(mydata,
centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares",
main="Assessing the Optimal Number of Clusters with the Elbow Method",
pch=20, cex=2)
mydata <- for_kmeans
k_values <- c(5, 7, 9)
for_kmeans <- Prestige[, list(women, income)]
mydata <- for_kmeans
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(mydata,
centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares",
main="Assessing the Optimal Number of Clusters with the Elbow Method",
pch=20, cex=2)
set.seed(250)
output <- kmeans(for_kmeans, centers=4)
Prestige[, kmean_type:=output$cluster]
##PlotB, plotting the predicted clusters with k=4
ggplot(Prestige, aes(x=women, y=income, color=factor(kmean_type))) +
geom_point() +
labs(title="Predicted Clusters, K=4")
l1 <- lm(prestige ~ income + education, data = Prestige)
summary(l1)
l2 <- lm(prestige ~ income + education + type, data = Prestige)
summary(l2)
anova(l1, l2)
any(is.na(Prestige$type))
l3 <- update(l1, subset = !is.na(type))
summary(l3)
anova(l3,l2)
anova(l1, l2)
l1 <- lm(prestige ~ income + education, data = Prestige)
summary(l1)
l2 <- lm(prestige ~ income + education + type, data = Prestige)
summary(l2)
anova(l1, l2)
any(is.na(Prestige$type))
l3 <- update(l1, subset = !is.na(type))
summary(l3)
anova(l3,l2)
ggplot(Prestige, aes(x=income, y=prestige)) + geom_point(aes(colour=type), alpha=0.5) + geom_smooth(method=lm, se=T) + labs(title="Income by Prestige and Type",
x="Income",
y="Prestige")
l1 <- lm(prestige ~ income + education, data = Prestige)
summary(l1)
anova
?anova
l3 <- update(l1, subset = !is.na(type))
summary(l3)
anova(l3,l2)
#Scatter plot of Prestige with education and type showing the trendline with standard error
ggplot(Prestige, aes(x=education, y=prestige)) + geom_point(aes(colour=type)) + geom_smooth(method=lm, se=T) + labs(title="Education by Prestige and Type",
x="Education",
y="Prestige")
#Scatter plot of Prestige with income and type showing the trendline with standard error
ggplot(Prestige, aes(x=income, y=prestige)) + geom_point(aes(colour=type), alpha=0.5) + geom_smooth(method=lm, se=T) + labs(title="Income by Prestige and Type",
x="Income",
y="Prestige")
?str
#Scatter plot of Prestige with income and type showing the trendline with standard error
ggplot(Prestige, aes(x=income, y=prestige)) + geom_point(aes(colour=type), alpha=0.5) + geom_smooth(method=lm, se=T) + labs(title="Income by Prestige and Type",
x="Income",
#Scatter plot of Prestige with income and type showing the trendline with standard error
ggplot(Prestige, aes(x=income, y=prestige)) + geom_point(aes(colour=type), alpha=0.5) + geom_smooth(method=lm, se=T) + labs(title="Income by Prestige and Type",
x="Income",
y="Prestige")
#Scatter plot of Prestige with income and type showing the trendline with standard error
ggplot(Prestige, aes(x=income, y=prestige)) + geom_point(aes(colour=type), alpha=0.5) + geom_smooth(method=lm, se=T) + labs(title="Income by Prestige and Type",
x="Income",
y="Prestige")
#Scatter plot of Prestige with income and type showing the trendline with standard error
ggplot(Prestige, aes(x=income, y=prestige)) + geom_point(aes(colour=type), alpha=0.5) + geom_smooth(method=lm, se=T) + labs(title="Income by Prestige and Type",
x="Income",
y="Prestige")
##Knn
#Scatter plot of Prestige with education and women
ggplot(Prestige, aes(x=education, y=prestige)) + geom_point(aes(colour=women)) + labs(title="Education by Prestige and Women",
x="Education",
y="Prestige")
#Scatter plot of Prestige with education and type showing the trendline with standard error
ggplot(Prestige, aes(x=education, y=prestige)) + geom_point(aes(colour=type)) + geom_smooth(method=lm, se=T) + labs(title="Education by Prestige and Type",
x="Education",
y="Prestige")
#Scatter plot of Prestige with income and type showing the trendline with standard error
ggplot(Prestige, aes(x=income, y=prestige)) + geom_point(aes(colour=type), alpha=0.5) + geom_smooth(method=lm, se=T) + labs(title="Income by Prestige and Type",
x="Income",
y="Prestige")
#Scatter plot of Prestige with log transformation of income, women and type using facet
ggplot(Prestige, aes(x=log2(income), y=prestige)) + geom_point(aes(colour=women)) + facet_grid(~type) + labs(title="Log2(Income) by Prestige, Income, Women and Type",
x="Log2(Income)", y="Prestige")
# fit a model excluding the variable education,  log the income variable.
multi_regression3 = lm(log(income) ~ prestige + women, data=multidata)
summary(multi_regression3)
multidata
